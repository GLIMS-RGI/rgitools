{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A semi-automated matching of the GAMDAM and RGI6 glacier inventories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook downloads and reads the GAMDAM glacier inventory, \"RGIifies\" it, and links it with RGI.\n",
    "\n",
    "We first try an automated matching in the direction RGI -> GAMDAM, since RGI seems to have less entries in general.\n",
    "We then write PDFs with plots around unmatched RGI polygons with neighboring GAMDAM glaciers. These have to be manually assessed (good luck!) and then eneterd into a list (CSV or so). Finally, there should be three lists left: \n",
    "\n",
    "1) a list with all matches from RGI to GAMDAM, \n",
    "\n",
    "2) a list with RGI polygons that don't have a GAMDAM partner, and \n",
    "\n",
    "3) a list with all GAMDAM polygons that don't have an RGI partner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import salem\n",
    "import shapely\n",
    "import oggm\n",
    "from oggm import cfg\n",
    "import zipfile\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do the OGGM initialization to make use of the download options (we might want to externalize this later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oggm.cfg.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "base_path = os.path.expanduser('~')\n",
    "regions = ['CentralAsia', 'NorthAsia', 'SouthAsiaEast', 'SouthAsiaWest']\n",
    "region = 'CentralAsia'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automated download of all GAMDAM shape files (make use of OGGM funcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_gamdam_file(base_path, region):\n",
    "    with oggm.utils.get_lock():\n",
    "        return _download_gamdam_file_unlocked(base_path, region)\n",
    "\n",
    "\n",
    "def _download_gamdam_file_unlocked(base_path, region):\n",
    "    fname = 'gamdam20180404_001_{}.zip'.format(region)\n",
    "    dest_file = os.path.join(base_path, fname)\n",
    "    oggm.utils._downloads._requests_urlretrieve('http://store.pangaea.de/Publications/Sakai_2018/{}'.format(\n",
    "        fname), dest_file, None, auth=None, timeout=None)\n",
    "\n",
    "    with zipfile.ZipFile(dest_file) as zf:\n",
    "        zf.extractall(os.path.dirname(dest_file))\n",
    "\n",
    "# do the job\n",
    "for r in regions:\n",
    "    download_gamdam_file(base_path, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Say what we want to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAMDAM file\n",
    "gfile = os.path.join(base_path, 'gamdam20180404_001_{}.shp'.format(region))\n",
    "\n",
    "\n",
    "# RGI file (glob to save region number)\n",
    "# spoiler: the RGI folders should be in base_path already\n",
    "rfile = glob(os.path.join(base_path, '**/*_rgi60_{}.shp'.format(region)))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here is the function that creates and fills RGI attributes, if they are straightforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgiify_gamdam(gamdam_gdf: gpd.GeoDataFrame, area_epsg: int = 5837) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Make an RGI imitation of the GAMDAM glacier inventory [1]_.\n",
    "    \n",
    "    Most of the attributes are just dummies, since it's not yet clear which DEM we want to use etc.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gamdam_gdf : geopandas.GeoDataFrame\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    gamdam_gdf: geopandas.GeoDataFrame\n",
    "        Same geometries as in the GAMDAM inventory, but with RGI attributes.\n",
    "    area_epsg: int\n",
    "        EPSG code for a projection to use to claculate the polygon area in metric units. Default: 3857 \n",
    "        (WGS 84 / Pseudo-Mercator), may not be the optimum though.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Sakai, A. (2019). Brief communication: Updated GAMDAM glacier\n",
    "           inventory over high-mountain Asia. The Cryosphere, 13(7), 2043-2049.\n",
    "    \"\"\"\n",
    "\n",
    "    gamdam_gdf['RGIId'] = ''\n",
    "    gamdam_gdf['GLIMSId'] = ''\n",
    "    gamdam_gdf['BgnDate'] = pd.to_datetime([f'{y}-{m}-{d}' for y, m, d in\n",
    "                                            zip(gamdam_gdf.yyyy,\n",
    "                                                gamdam_gdf.mm,\n",
    "                                                gamdam_gdf.dd)])\n",
    "    del gamdam_gdf['yyyy']\n",
    "    del gamdam_gdf['mm']\n",
    "    del gamdam_gdf['dd']\n",
    "    gamdam_gdf['EndDate'] = gamdam_gdf['BgnDate'].copy(deep=True)\n",
    "    centroids = gamdam_gdf.geometry.centroid\n",
    "    gamdam_gdf['CenLon'] = [p.x for p in centroids]\n",
    "    gamdam_gdf['CenLat'] = [p.y for p in centroids]\n",
    "    gamdam_gdf['O1Region'] = ''\n",
    "    gamdam_gdf['O2Region'] = ''\n",
    "    gamdam_reproj = gamdam_gdf.to_crs(epsg=area_epsg)\n",
    "    gamdam_gdf['Area'] = gamdam_reproj.geometry.area / 10**6\n",
    "    gamdam_gdf['Zmin'] = np.nan\n",
    "    gamdam_gdf['Zmax'] = np.nan\n",
    "    gamdam_gdf['Zmed'] = np.nan\n",
    "    gamdam_gdf['Slope'] = np.nan\n",
    "    gamdam_gdf['Aspect'] = np.nan\n",
    "    gamdam_gdf['Lmax'] = np.nan\n",
    "    gamdam_gdf['Status'] = np.nan\n",
    "    gamdam_gdf['Connect'] = np.nan\n",
    "    gamdam_gdf['Form'] = np.nan\n",
    "    gamdam_gdf['TermType'] = np.nan\n",
    "    gamdam_gdf['Surging'] = np.nan\n",
    "    gamdam_gdf['Linkages'] = np.nan\n",
    "    gamdam_gdf['Name'] = ''\n",
    "\n",
    "    return gamdam_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read\n",
    "gamdam = salem.read_shapefile(gfile)\n",
    "rgi6 = salem.read_shapefile(rfile)\n",
    "\n",
    "# set CRS (missing)\n",
    "gamdam.crs = {'init' :'epsg:4326'}\n",
    "rgi6.crs = {'init' :'epsg:4326'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at the headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamdam.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgi6.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do the \"RGIifying\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgam = rgiify_gamdam(gamdam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set some search parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many potential GAMDAM neighbors in the vicinity of an RGI polygon to consider\n",
    "consider_closest = 20\n",
    "# This thrshold determines how high a threshold has to be to make it a match\n",
    "overlap_ratio = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automated matching approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On vierzack06 (ETH server), the processing corrently takes ~5min for 1000 glaciers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomatch = []\n",
    "for i, rgirow in rgi6[:100].iterrows():\n",
    "    pct_overlap = []\n",
    "    rgiframe = gpd.GeoDataFrame([rgirow], geometry='geometry')\n",
    "    rgi_area = rgiframe.geometry.area.values\n",
    "    \n",
    "    hdist = oggm.utils.haversine(rgirow.CenLon, rgirow.CenLat, rgam.CenLon, rgam.CenLat)\n",
    "    rgam['hdist'] = hdist\n",
    "    rgam.sort_values(by='hdist', inplace=True)\n",
    "    rgam_sel = rgam.head(consider_closest)\n",
    "    for j, gamdamrow in rgam_sel.iterrows():\n",
    "        gamframe = gpd.GeoDataFrame([gamdamrow], geometry='geometry')\n",
    "        gamdam_area = gamframe.geometry.area.values\n",
    "        intsct_area = gpd.overlay(gamframe, rgiframe, how='intersection').geometry.area.values\n",
    "        \n",
    "        # no intersection\n",
    "        if (intsct_area).size == 0:\n",
    "            continue \n",
    "        \n",
    "        # check: either RGI can be in GAMDAM or the other way around\n",
    "        intsct_ratio_one = intsct_area / gamdam_area\n",
    "        intsct_ratio_two = intsct_area / rgi_area\n",
    "        intsct_ratio = np.max([intsct_ratio_one, intsct_ratio_two])\n",
    "        pct_overlap.append(intsct_ratio)\n",
    "        \n",
    "    if (i % 100) == 0:\n",
    "        print(i)\n",
    "        \n",
    "    if ~(np.array(pct_overlap) > overlap_ratio).any():\n",
    "        print('No Match: ', rgirow.RGIId)\n",
    "        nomatch.append(rgirow.RGIId)\n",
    "        continue\n",
    "    best_match = np.argmax(np.array(pct_overlap))\n",
    "    \n",
    "    rgam.loc[rgam.FID_1 == rgam_sel.iloc[best_match].FID_1, 'RGIId'] = rgirow.RGIId"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shapefile doesn't like date objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgam['BgnDate'] = rgam['BgnDate'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "rgam['EndDate'] = rgam['EndDate'].apply(lambda x: x.strftime('%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgam.to_file(os.path.join(base_path, 'RGI_GAMDAM_links_automated_{}.shp'.format(region)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write all unmatched glaciers (RGI -> GAMDAM) to PDF plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'{} Glaciers are unmatched in the automated approach.'.format(len(nomatch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pack plots into batches of 50 plots per PDF, otherwise the PDF file size becomes very large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "region = 'CentralAsia'\n",
    "plot_closest = 10\n",
    "curr = 1  # current plot\n",
    "unmatched_ids = nomatch.copy()\n",
    "total = len(unmatched_ids)  # total number of plots ()\n",
    "batch_size = 50\n",
    "\n",
    "pdf_batches = np.arange(0, total + batch_size, batch_size)\n",
    "\n",
    "for k, (start, end) in enumerate(zip(pdf_batches[:-1], pdf_batches[1:])):\n",
    "    with PdfPages(os.path.join(base_path, 'RGI_GAMDAM_manual_checks_{}_{}.pdf'.format(region, k))) as pdf:\n",
    "        for gid in unmatched_ids[start:end]:\n",
    "            glacier = rgi6[rgi6.RGIId == gid].iloc[0]\n",
    "            lon, lat = glacier.CenLon, glacier.CenLat\n",
    "            hdist = curr_dist = oggm.utils.haversine(glacier.CenLon, glacier.CenLat, rgam.CenLon, rgam.CenLat)\n",
    "            rgam['hdist'] = hdist\n",
    "            rgam.sort_values(by='hdist', inplace=True)\n",
    "            \n",
    "            rgam_sel = rgam.head(plot_closest)\n",
    "\n",
    "            # For GoogleMap we need a lon lat range to generate the map\n",
    "            mmlon = [lon, lon]\n",
    "            mmlat = [lat, lat]\n",
    "            \n",
    "            bminx, bminy, bmaxx, bmaxy = rgam_sel.total_bounds\n",
    "            mmlon = [np.min(np.append(mmlon, bminx)), np.max(np.append(mmlon, bmaxx))]\n",
    "            mmlat = [np.min(np.append(mmlat, bminy)), np.max(np.append(mmlat, bmaxy))]\n",
    "\n",
    "            # Make a local map where to plot the polygons\n",
    "            local = salem.GoogleVisibleMap(x=mmlon, y=mmlat) # also possible:  maptype='terrain'\n",
    "            local_map = salem.Map(local.grid, countries=False, nx=640)\n",
    "            local_map.set_lonlat_contours()\n",
    "\n",
    "\n",
    "            # Prepare the figure\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "            ax1.set_title('{}: '.format(gid) + glacier.O1Region + '-' + str(glacier.Name) + \n",
    "                         ' {:.2f}km2'.format(glacier.Area))\n",
    "\n",
    "            # Plot glaciers\n",
    "            colors = ['red', 'orange', 'green', 'blue', 'purple', 'magenta', 'chartreuse', 'brown', 'black',\n",
    "                      'yellow']\n",
    "            for i in np.arange(0, plot_closest):\n",
    "                gamg = rgam_sel.iloc[i]\n",
    "                # In case the glacier is a MultiPolygon we (again) account for this here:\n",
    "                if gamg.geometry.type == 'Polygon':\n",
    "                    x, y = gamg.geometry.exterior.xy\n",
    "                elif gamg.geometry.type == 'MultiPolygon':\n",
    "                    # buffer is necessary as some multi-polygons are self-intersecting\n",
    "                    allparts = [p.buffer(0) for p in gamg.geometry] \n",
    "                    gamg.geometry = shapely.ops.cascaded_union(allparts)\n",
    "                    x, y = gamg.geometry.exterior.xy\n",
    "\n",
    "                #  print centroid of matching glacier\n",
    "                if i == 0:\n",
    "                    local_map.set_geometry(shapely.geometry.Point(gamg.CenLon, gamg.CenLat), edgecolor='k',\n",
    "                                           marker='x', color='g', linewidth=4, markersize=100, zorder=50, text='GAMDAM',  text_delta=(0.02, 0.02))\n",
    "\n",
    "                # RGI polygon label\n",
    "                if gamg.Name == '':\n",
    "                    plabel =  'ID: ' + str(gamg.FID_1)+'\\n'+str(round(gamg.Area, 2))+'km2'  + ', HDIST: ' + str(int(gamg.hdist))+'m'\n",
    "                else:\n",
    "                    plabel =  'ID: ' + str(gamg.FID_1)+'\\n'+str(round(gamg.Area, 2))+'km2\\n'+str(gamg.Name) + ', HDIST: ' + str(int(gamg.hdist))+'m'\n",
    "\n",
    "                local_map.set_geometry(gamg.geometry.exterior, color=colors[i], linewidth=3, label=plabel)\n",
    "\n",
    "                local_map.set_geometry(shapely.geometry.Point(gamg.CenLon, gamg.CenLat), c='k', marker='x', markersize=30, zorder=51) #again adjusted fpr RGI 5.0\n",
    "\n",
    "            local_map.set_geometry(shapely.geometry.Point(lon, lat), color='g', marker='x', linewidth=4, markersize=100, zorder=50, text='RGI', text_delta=(0.02, 0.02))\n",
    "            local_map.set_geometry(glacier.geometry.exterior, color='darkblue', linewidth=3, label=glacier.RGIId)\n",
    "            \n",
    "            local_map.set_rgb(local.get_vardata())\n",
    "            local_map.visualize(ax=ax1, addcbar=False)\n",
    "\n",
    "            local = salem.GoogleVisibleMap(x=mmlon, y=mmlat, maptype='terrain')\n",
    "            local_map.set_rgb(local.get_vardata())\n",
    "            local_map.visualize(ax=ax2, addcbar=False)\n",
    "            plt.subplots_adjust(left=0.04, right=0.80, top=0.94, bottom=0.07)\n",
    "            plt.legend(bbox_to_anchor=(1.02, 1.), fontsize=12, loc=2, borderaxespad=0, frameon=False, numpoints=1,scatterpoints=1)\n",
    "            pdf.savefig(fig)\n",
    "            plt.close()\n",
    "\n",
    "            if curr % 5 == 0:\n",
    "                print('{} / {} plots done.'.format(curr, total))\n",
    "            curr += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unmatched RGI polygons by area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgi_sub = rgi6.loc[rgi6.RGIId.isin(nomatch)]\n",
    "plt.figure()\n",
    "rgi_sub.Area.hist(bins=500)\n",
    "plt.xlabel('Area (km2)')\n",
    "plt.ylabel('No. of unmatched')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a CSV where all unmatched RGI polygons can get a partner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_outpath = os.path.join(base_path, 'unmatched_rgi_gamdam_{}.csv'.format(region))\n",
    "\n",
    "unmatched_df = pd.DataFrame(data=np.array([nomatch, np.full_like(nomatch, np.nan)]).T, \n",
    "                            columns=['RGIId', 'GAMDAM_ID'])\n",
    "unmatched_df.to_csv(csv_outpath)                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclude by listing the GAMDAM glaciers which are unmatched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This list will contain all GAMDAM glaciers that haven't been successfully matched \n",
    "1) During the automated RGI -> GAMDAM search\n",
    "2) During the manual RGI -> GAMDAM search\n",
    "This means the list will contain all row of `rgam`, which to do have an try in the RGI column after the autmated search, MINUS all sucessful matches during the manual matching."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rgitools",
   "language": "python",
   "name": "rgitools"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
